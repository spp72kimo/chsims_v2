{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d9cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# CH-SIMS V2 + V-JEPA 2: å…©éšæ®µ Fine-tune\n",
    "# Google Colab ç‰ˆï¼ˆå¾ Drive è¤‡è£½ Raw.zipï¼‰\n",
    "# ==========================================\n",
    "\n",
    "# ==========================================\n",
    "# Step 1. æ›è¼‰ Google Drive\n",
    "# ==========================================\n",
    "!pip install -q \"transformers[torch]\" decord\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ==========================================\n",
    "# Step 2. å¾å·²æ›è¼‰çš„ Google Drive è¤‡è£½ Raw.zip ä¸¦è§£å£“ç¸®\n",
    "# ==========================================\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "def copy_with_progress(src, dst, buffer_size=1024*1024*16):\n",
    "    total_size = os.path.getsize(src)\n",
    "    with open(src, 'rb') as fsrc, open(dst, 'wb') as fdst:\n",
    "        with tqdm(total=total_size, unit='B', unit_scale=True, desc=\"Copying zip\") as pbar:\n",
    "            while True:\n",
    "                buf = fsrc.read(buffer_size)\n",
    "                if not buf:\n",
    "                    break\n",
    "                fdst.write(buf)\n",
    "                pbar.update(len(buf))\n",
    "\n",
    "# ===== è¨­å®šè·¯å¾‘ =====\n",
    "target_dir = '/content/datasets'\n",
    "extract_dir = os.path.join(target_dir, 'CH-SIMS-V2')\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# ä¾†æºï¼šæ›è¼‰å¥½çš„ Google Drive\n",
    "src_path = '/content/drive/MyDrive/datasets/CH-SIMS-V2/Raw.zip'\n",
    "dst_path = os.path.join(target_dir, 'Raw.zip')\n",
    "\n",
    "# ===== æª¢æŸ¥ä¾†æºæª”æ¡ˆ =====\n",
    "if not os.path.exists(src_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"âŒ æ‰¾ä¸åˆ°ä¾†æºæª”æ¡ˆï¼š{src_path}\\n\"\n",
    "        \"è«‹ç¢ºèª Raw.zip å·²æ”¾åœ¨ MyDrive/datasets/CH-SIMS-V2/ åº•ä¸‹ã€‚\"\n",
    "    )\n",
    "\n",
    "# ===== å¾ Drive è¤‡è£½åˆ°æœ¬åœ°ï¼ˆ/content/datasetsï¼‰=====\n",
    "if not os.path.exists(dst_path):\n",
    "    print(f\"ğŸ“¥ å¾ Google Drive è¤‡è£½ Raw.zip åˆ° {dst_path} ...\")\n",
    "    copy_with_progress(src_path, dst_path)\n",
    "    print(\"âœ… è¤‡è£½å®Œæˆï¼\")\n",
    "else:\n",
    "    print(f\"â© {dst_path} å·²å­˜åœ¨ï¼Œè·³éè¤‡è£½ã€‚\")\n",
    "\n",
    "# æª¢æŸ¥æª”æ¡ˆå¤§å°\n",
    "if os.path.exists(dst_path):\n",
    "    file_size_gb = os.path.getsize(dst_path) / (1024**3)\n",
    "    print(f\"æª”æ¡ˆå¤§å°: {file_size_gb:.2f} GB\")\n",
    "\n",
    "# ===== è§£å£“ç¸® =====\n",
    "if not os.path.exists(extract_dir):\n",
    "    print(f\"ğŸ“‚ è§£å£“ç¸® {dst_path} åˆ° {extract_dir} ...\")\n",
    "    with zipfile.ZipFile(dst_path, 'r') as zip_ref:\n",
    "        file_list = zip_ref.namelist()\n",
    "        print(f\"å£“ç¸®æª”åŒ…å« {len(file_list)} å€‹é …ç›®\")\n",
    "        for file in tqdm(file_list, desc=\"è§£å£“ç¸®ä¸­\", unit=\"files\"):\n",
    "            zip_ref.extract(file, extract_dir)\n",
    "    print(\"âœ… è§£å£“ç¸®å®Œæˆï¼\")\n",
    "else:\n",
    "    print(f\"â© {extract_dir} å·²å­˜åœ¨ï¼Œè·³éè§£å£“ç¸®ã€‚\")\n",
    "\n",
    "print(\"\\nğŸ“ æª¢æŸ¥è³‡æ–™çµæ§‹...\")\n",
    "\n",
    "# ä¾æ“šå¯¦éš›è§£å£“çµæœï¼Œä½ ä¹‹å‰çš„ log é¡¯ç¤ºçµæ§‹å¦‚ä¸‹ï¼š\n",
    "# /content/datasets/CH-SIMS-V2/ch-simsv2s/{meta.csv, Raw/}\n",
    "root_level = os.listdir(extract_dir)\n",
    "print(\"CH-SIMS-V2 åº•ä¸‹å…§å®¹ï¼š\", root_level)\n",
    "\n",
    "data_root_path = os.path.join(extract_dir, 'ch-simsv2s')\n",
    "if not os.path.exists(data_root_path):\n",
    "    print(\"âŒ æ‰¾ä¸åˆ° ch-simsv2sï¼Œå¯¦éš›çµæ§‹å¦‚ä¸‹ï¼š\")\n",
    "    !ls -R {extract_dir} | head -n 80\n",
    "    raise FileNotFoundError(\"è«‹ç¢ºèª zip è£¡çš„è³‡æ–™å¤¾åç¨±æ˜¯å¦ç‚º ch-simsv2s\")\n",
    "\n",
    "raw_folder = os.path.join(data_root_path, 'Raw')\n",
    "if os.path.exists(raw_folder):\n",
    "    video_folders = [d for d in os.listdir(raw_folder)\n",
    "                     if os.path.isdir(os.path.join(raw_folder, d))]\n",
    "    print(f\"âœ… æ‰¾åˆ° Raw è³‡æ–™å¤¾ï¼š{raw_folder}\")\n",
    "    print(f\"   å…±æœ‰ {len(video_folders)} å€‹å½±ç‰‡è³‡æ–™å¤¾\")\n",
    "    print(\"   ç¯„ä¾‹è³‡æ–™å¤¾ï¼š\", video_folders[:10])\n",
    "else:\n",
    "    print(\"âŒ æ‰¾ä¸åˆ° Raw è³‡æ–™å¤¾ï¼\")\n",
    "    !ls -R {data_root_path} | head -n 80\n",
    "    raise FileNotFoundError(\"Raw è³‡æ–™å¤¾ä¸å­˜åœ¨ï¼Œè«‹ç¢ºèªè³‡æ–™é›†å£“ç¸®æª”çµæ§‹\")\n",
    "\n",
    "# ===== æª¢æŸ¥ meta.csv =====\n",
    "meta_csv_path = os.path.join(data_root_path, 'meta.csv')\n",
    "if os.path.exists(meta_csv_path):\n",
    "    print(f\"âœ… æ‰¾åˆ° meta.csvï¼š{meta_csv_path}\")\n",
    "else:\n",
    "    print(\"âŒ æ‰¾ä¸åˆ° meta.csvï¼\")\n",
    "    !find {extract_dir} -name \"meta.csv\"\n",
    "    raise FileNotFoundError(\"meta.csv æœªæ‰¾åˆ°ï¼Œè«‹ç¢ºèªè³‡æ–™é›†çµæ§‹\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è³‡æ–™æº–å‚™å®Œæˆï¼\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ===== è¤‡è£½ä¸¦è§£å£“ç¸® bbox_cache =====\n",
    "bbox_cache_name = \"bbox_cache_merged\"\n",
    "bbox_cache_src = f'/content/drive/MyDrive/datasets/CH-SIMS-V2/{bbox_cache_name}.zip'\n",
    "bbox_cache_local_zip = os.path.join(target_dir, f'{bbox_cache_name}.zip')\n",
    "bbox_cache_dir = os.path.join(target_dir, 'CH-SIMS-V2', bbox_cache_name)\n",
    "\n",
    "# æª¢æŸ¥æ˜¯å¦æœ‰å£“ç¸®æª”ï¼ˆå¦‚æœ Drive ä¸Šæ˜¯è³‡æ–™å¤¾è€Œé zipï¼Œè¦‹ä¸‹æ–¹æ›¿ä»£æ–¹æ¡ˆï¼‰\n",
    "if os.path.exists(bbox_cache_src):\n",
    "    # è¤‡è£½ zip åˆ°æœ¬åœ°\n",
    "    if not os.path.exists(bbox_cache_local_zip):\n",
    "        print(f\"ğŸ“¥ è¤‡è£½ {bbox_cache_name}.zip åˆ°æœ¬åœ°...\")\n",
    "        shutil.copy2(bbox_cache_src, bbox_cache_local_zip)\n",
    "        print(\"âœ… è¤‡è£½å®Œæˆï¼\")\n",
    "    else:\n",
    "        print(f\"â© {bbox_cache_local_zip} å·²å­˜åœ¨ï¼Œè·³éè¤‡è£½ã€‚\")\n",
    "\n",
    "    # è§£å£“ç¸®\n",
    "    if not os.path.exists(bbox_cache_dir):\n",
    "        print(f\"ğŸ“‚ è§£å£“ç¸® {bbox_cache_name}.zip...\")\n",
    "        with zipfile.ZipFile(bbox_cache_local_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.join(target_dir, 'CH-SIMS-V2'))\n",
    "        print(\"âœ… è§£å£“ç¸®å®Œæˆï¼\")\n",
    "    else:\n",
    "        print(f\"â© {bbox_cache_dir} å·²å­˜åœ¨ï¼Œè·³éè§£å£“ç¸®ã€‚\")\n",
    "else:\n",
    "    # å¦‚æœ Drive ä¸Šæ˜¯è³‡æ–™å¤¾è€Œé zipï¼Œç›´æ¥è¤‡è£½æ•´å€‹è³‡æ–™å¤¾\n",
    "    print(\"è®€å–èˆŠçš„ bbox_cacheï¼Œè«‹ç¢ºèª bbox_cache zip name\")\n",
    "    bbox_cache_folder_src = '/content/drive/MyDrive/datasets/CH-SIMS-V2/bbox_cache'\n",
    "\n",
    "    if os.path.exists(bbox_cache_folder_src):\n",
    "        if not os.path.exists(bbox_cache_dir):\n",
    "            print(f\"ğŸ“¥ è¤‡è£½ bbox_cache è³‡æ–™å¤¾åˆ°æœ¬åœ°ï¼ˆé€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜ï¼‰...\")\n",
    "            shutil.copytree(bbox_cache_folder_src, bbox_cache_dir)\n",
    "            print(\"âœ… è¤‡è£½å®Œæˆï¼\")\n",
    "        else:\n",
    "            print(f\"â© {bbox_cache_dir} å·²å­˜åœ¨ï¼Œè·³éè¤‡è£½ã€‚\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æ‰¾ä¸åˆ° bbox_cacheï¼Œå°‡ä¸ä½¿ç”¨ ASD è£åˆ‡\")\n",
    "        bbox_cache_dir = None\n",
    "\n",
    "# æª¢æŸ¥ bbox_cache å…§å®¹\n",
    "if bbox_cache_dir and os.path.exists(bbox_cache_dir):\n",
    "    import glob\n",
    "    cache_files = glob.glob(os.path.join(bbox_cache_dir, \"**\", \"*.json\"), recursive=True)\n",
    "    print(f\"âœ… bbox_cache åŒ…å« {len(cache_files)} å€‹ JSON æª”æ¡ˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸ bbox_cache ä¸å­˜åœ¨æˆ–ç‚ºç©º\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"è³‡æ–™æº–å‚™å®Œæˆï¼\")\n",
    "# print(\"=\"*60)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
